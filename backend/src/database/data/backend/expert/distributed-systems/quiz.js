// ============================================================================
// Distributed Systems — Quiz Questions
// ============================================================================

const quiz = {
  'cap-theorem-consistency': [
    {
      question_text: 'What does the CAP theorem state about distributed systems?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'A distributed system can achieve Consistency, Availability, and Partition Tolerance simultaneously',
        'A distributed system can guarantee at most two of three: Consistency, Availability, Partition Tolerance',
        'A distributed system must sacrifice performance for reliability',
        'A distributed system always chooses consistency over availability',
      ]),
      correct_answer: 'A distributed system can guarantee at most two of three: Consistency, Availability, Partition Tolerance',
      explanation: 'The CAP theorem (Brewer\'s theorem) states that in the presence of a network partition, a distributed system must choose between consistency and availability — it cannot guarantee all three simultaneously.',
      difficulty: 'hard',
      order_index: 1,
    },
    {
      question_text: 'In practice, why is Partition Tolerance considered mandatory in distributed systems?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'Because partitions improve performance',
        'Because network partitions are inevitable in real distributed systems',
        'Because the CAP theorem requires it',
        'Because partition tolerance is the cheapest to implement',
      ]),
      correct_answer: 'Because network partitions are inevitable in real distributed systems',
      explanation: 'Network partitions (message loss, delays, network splits) are unavoidable in real-world distributed systems. Since you cannot prevent them, you must tolerate them — making the real choice between CP and AP.',
      difficulty: 'hard',
      order_index: 2,
    },
    {
      question_text: 'Which consistency model guarantees that operations appear to take effect instantaneously at some point between invocation and completion?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'Eventual consistency',
        'Sequential consistency',
        'Linearizability',
        'Causal consistency',
      ]),
      correct_answer: 'Linearizability',
      explanation: 'Linearizability (also called atomic consistency) is the strongest single-object consistency model. It guarantees that each operation appears to execute atomically at some point between its start and end, respecting real-time ordering.',
      difficulty: 'hard',
      order_index: 3,
    },
    {
      question_text: 'Apache Cassandra is typically classified as which type of system under CAP?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'CA — Consistent and Available',
        'CP — Consistent and Partition Tolerant',
        'AP — Available and Partition Tolerant',
        'CAP — All three',
      ]),
      correct_answer: 'AP — Available and Partition Tolerant',
      explanation: 'Cassandra is an AP system by default — it prioritizes availability and partition tolerance, using eventual consistency. Writes are always accepted even during partitions, and consistency is tunable per-query.',
      difficulty: 'hard',
      order_index: 4,
    },
    {
      question_text: 'What is the purpose of vector clocks in distributed systems?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'Synchronize wall-clock time across nodes',
        'Track causal relationships and detect concurrent operations',
        'Measure network latency between nodes',
        'Order events by their physical timestamps',
      ]),
      correct_answer: 'Track causal relationships and detect concurrent operations',
      explanation: 'Vector clocks maintain a logical clock per node, allowing precise detection of causal ordering (happened-before) and concurrent operations. Unlike Lamport timestamps, vector clocks can definitively determine if two events are concurrent.',
      difficulty: 'hard',
      order_index: 5,
    },
    {
      question_text: 'What does the PACELC theorem add to CAP?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'It addresses the trade-off between Price and Consistency',
        'It extends CAP to include Latency vs Consistency trade-offs when there is no partition',
        'It replaces the CAP theorem with a more accurate model',
        'It proves that all three CAP properties can be achieved',
      ]),
      correct_answer: 'It extends CAP to include Latency vs Consistency trade-offs when there is no partition',
      explanation: 'PACELC states: if Partitioned, choose Availability or Consistency (PAC); Else (no partition), choose Latency or Consistency (ELC). This captures the everyday trade-off systems make even when the network is healthy.',
      difficulty: 'hard',
      order_index: 6,
    },
    {
      question_text: 'In a quorum-based system with N=5 replicas, what is the minimum write quorum (W) and read quorum (R) needed for strong consistency?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'W=1, R=1',
        'W=2, R=2',
        'W=3, R=3',
        'W=5, R=5',
      ]),
      correct_answer: 'W=3, R=3',
      explanation: 'Strong consistency requires W + R > N. With N=5, setting W=3 and R=3 gives W+R=6 > 5, ensuring at least one node in the read quorum has the latest write. W=2, R=2 would give only 4, which is not greater than 5.',
      difficulty: 'hard',
      order_index: 7,
    },
    {
      question_text: 'What is "read repair" in eventually consistent systems?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'Repairing corrupted data during compaction',
        'Fixing stale replicas encountered during a read by sending the latest value to them',
        'Re-reading data from the primary when a read fails',
        'Using checksums to verify data integrity on read',
      ]),
      correct_answer: 'Fixing stale replicas encountered during a read by sending the latest value to them',
      explanation: 'Read repair is an anti-entropy mechanism where, upon reading from multiple replicas, the coordinator identifies stale copies and updates them with the most recent version. This opportunistically improves consistency as data is accessed.',
      difficulty: 'hard',
      order_index: 8,
    },
    {
      question_text: 'What is the key limitation of Lamport timestamps compared to vector clocks?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'Lamport timestamps require more network bandwidth',
        'Lamport timestamps cannot definitively identify concurrent events',
        'Lamport timestamps are harder to implement',
        'Lamport timestamps do not support more than two nodes',
      ]),
      correct_answer: 'Lamport timestamps cannot definitively identify concurrent events',
      explanation: 'If Lamport timestamp A < B, you know A might have happened before B — but they could also be concurrent. Lamport timestamps establish a total order but cannot distinguish causality from concurrency. Vector clocks solve this by tracking each node\'s clock independently.',
      difficulty: 'hard',
      order_index: 9,
    },
    {
      question_text: 'In eventual consistency, what guarantees does the system provide?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'All reads always return the most recent write',
        'If no new writes occur, all replicas will eventually converge to the same value',
        'Replicas never diverge during normal operation',
        'Data is consistent within a fixed time bound',
      ]),
      correct_answer: 'If no new writes occur, all replicas will eventually converge to the same value',
      explanation: 'Eventual consistency guarantees convergence: given enough time without new writes, all replicas will have the same data. It does NOT guarantee when convergence happens or that reads return the latest write during the convergence period.',
      difficulty: 'hard',
      order_index: 10,
    },
  ],

  'distributed-transactions-saga': [
    {
      question_text: 'What is the main problem that the Saga pattern solves?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'Improving query performance across databases',
        'Maintaining data consistency across multiple services without distributed ACID transactions',
        'Reducing network latency between microservices',
        'Implementing service discovery in microservice architectures',
      ]),
      correct_answer: 'Maintaining data consistency across multiple services without distributed ACID transactions',
      explanation: 'Sagas maintain data consistency across services by breaking a distributed transaction into a sequence of local transactions, each with a compensating action. This avoids the performance and availability problems of distributed ACID transactions (2PC).',
      difficulty: 'hard',
      order_index: 1,
    },
    {
      question_text: 'In Two-Phase Commit (2PC), what happens if the coordinator crashes after sending PREPARE but before sending COMMIT/ABORT?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'Participants automatically commit after a timeout',
        'Participants automatically abort after a timeout',
        'Participants are blocked, holding locks until the coordinator recovers',
        'A new coordinator is immediately elected and takes over',
      ]),
      correct_answer: 'Participants are blocked, holding locks until the coordinator recovers',
      explanation: 'This is the critical "blocking problem" of 2PC. After voting YES in the prepare phase, participants hold locks and cannot decide independently — they must wait for the coordinator to recover and send the final COMMIT or ABORT decision.',
      difficulty: 'hard',
      order_index: 2,
    },
    {
      question_text: 'What is the key difference between choreography-based and orchestration-based sagas?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'Choreography is synchronous; orchestration is asynchronous',
        'Choreography uses events with no central coordinator; orchestration has a central coordinator directing the flow',
        'Choreography only works with two services; orchestration supports many',
        'Choreography is for simple CRUD; orchestration is for complex queries',
      ]),
      correct_answer: 'Choreography uses events with no central coordinator; orchestration has a central coordinator directing the flow',
      explanation: 'In choreography, each service publishes events and listens for others — there is no central controller. In orchestration, a saga orchestrator tells each service what to do and handles the overall flow. Orchestration is easier to debug but creates a central point of failure.',
      difficulty: 'hard',
      order_index: 3,
    },
    {
      question_text: 'What is a "compensating transaction" in the context of the Saga pattern?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'A transaction that runs faster to compensate for slow previous steps',
        'An action that semantically undoes the effect of a previously completed local transaction',
        'A backup transaction stored in case the primary fails',
        'A read-only transaction used for monitoring',
      ]),
      correct_answer: 'An action that semantically undoes the effect of a previously completed local transaction',
      explanation: 'Compensating transactions undo the business effect of a completed step. Unlike database rollbacks, they are application-level operations (e.g., issuing a refund to compensate for a charge, releasing reserved inventory). They may not restore exact original state but achieve a business-equivalent reversal.',
      difficulty: 'hard',
      order_index: 4,
    },
    {
      question_text: 'What problem does the Outbox Pattern solve?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'Database connection pooling',
        'The dual-write problem — atomically updating a database and publishing an event',
        'Message queue overflow',
        'Service discovery in distributed systems',
      ]),
      correct_answer: 'The dual-write problem — atomically updating a database and publishing an event',
      explanation: 'The dual-write problem occurs when you need to update a database AND publish an event — if one succeeds and the other fails, you have inconsistency. The Outbox Pattern writes both to the database in a single transaction, then a separate process reads the outbox and publishes events.',
      difficulty: 'hard',
      order_index: 5,
    },
    {
      question_text: 'What are the three states of a Circuit Breaker?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'Active, Inactive, Standby',
        'Closed, Open, Half-Open',
        'Running, Stopped, Paused',
        'Healthy, Unhealthy, Recovering',
      ]),
      correct_answer: 'Closed, Open, Half-Open',
      explanation: 'Closed = normal operation (requests flow through); Open = circuit tripped (requests are rejected/fallback); Half-Open = testing recovery (limited requests allowed through). After enough successes in Half-Open, it transitions back to Closed.',
      difficulty: 'hard',
      order_index: 6,
    },
    {
      question_text: 'Why is idempotency important in distributed systems?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'It makes operations run faster',
        'It ensures operations produce the same result regardless of how many times they are executed',
        'It prevents all types of race conditions',
        'It eliminates the need for error handling',
      ]),
      correct_answer: 'It ensures operations produce the same result regardless of how many times they are executed',
      explanation: 'In distributed systems, network failures and retries are common. Idempotent operations can be safely retried without causing unintended side effects (e.g., double-charging a customer). This is achieved through idempotency keys, deduplication, and conditional writes.',
      difficulty: 'hard',
      order_index: 7,
    },
    {
      question_text: 'When should you prefer orchestration-based sagas over choreography?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'When you have only 2 services involved',
        'When the saga has 4+ steps and complex compensation logic',
        'When you want maximum service decoupling',
        'When you want to avoid single points of failure',
      ]),
      correct_answer: 'When the saga has 4+ steps and complex compensation logic',
      explanation: 'Orchestration centralizes the saga flow in one place, making complex multi-step workflows easier to understand, debug, and modify. Choreography becomes increasingly hard to follow and test as the number of services and steps grows.',
      difficulty: 'hard',
      order_index: 8,
    },
    {
      question_text: 'In the Outbox Pattern, what technique allows multiple publisher instances to process the outbox concurrently without conflicts?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        'Optimistic locking with version numbers',
        'SELECT ... FOR UPDATE SKIP LOCKED',
        'Global mutex across all instances',
        'Round-robin assignment of outbox rows',
      ]),
      correct_answer: 'SELECT ... FOR UPDATE SKIP LOCKED',
      explanation: 'FOR UPDATE SKIP LOCKED in PostgreSQL allows concurrent publishers to each lock and process different rows from the outbox table. Publishers that encounter already-locked rows simply skip them, avoiding contention and deadlocks while ensuring every event is processed exactly once.',
      difficulty: 'hard',
      order_index: 9,
    },
    {
      question_text: 'What is the primary disadvantage of Two-Phase Commit (2PC) compared to the Saga pattern?',
      question_type: 'multiple_choice',
      options: JSON.stringify([
        '2PC is more complex to implement',
        '2PC does not guarantee atomicity',
        '2PC is a blocking protocol that holds locks until all participants respond',
        '2PC requires more network messages',
      ]),
      correct_answer: '2PC is a blocking protocol that holds locks until all participants respond',
      explanation: '2PC\'s biggest weakness is that it blocks — participants hold database locks during the prepare phase and cannot release them until the coordinator sends COMMIT or ABORT. This reduces throughput and availability, especially if the coordinator is slow or fails.',
      difficulty: 'hard',
      order_index: 10,
    },
  ],
};

export default quiz;
